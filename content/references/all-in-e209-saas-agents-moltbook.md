# All-In Podcast E209 - SaaS Crash, AI Agents, Moltbook
**Source:** https://www.youtube.com/watch?v=wTiHheA40nI
**Date:** ~Feb 4-5, 2026
**Speakers:** Jason Calacanis, David Sacks, Brad Gerstner, David Friedberg

## Key Themes for THE FUTURE

### 1. The SaaS Stock Crash
- $300B wiped from S&P software/data stocks in a single Tuesday
- Called "The Claude Crash" by some - triggered by Anthropic announcing legal tools in Claude Co-work
- Thompson Reuters down 20%, LexisNexis down 15%, LegalZoom down 15%
- Figma down 80% from highs overall
- Software trading at all-time low: 3.9x forward revenue
- **Key insight (Gerstner):** Revenue is stable/increasing. Stocks are falling because investors are discounting future certainty. Salesforce went from 30x to 15x free cash flow - investors used to bet 30 years ahead, now they only trust 15 years. Nobody knows what happens 7 years out.

### 2. SaaS Isn't Dead - But the Value Moves
- Sacks: "SaaS is dead" is overstated. You won't replace Salesforce with AI-generated code overnight. Millions of bug fixes, tested across thousands of enterprises.
- **But:** the risk is the value capture moves to a new layer. SaaS becomes "legacy infrastructure" - the action moves to the agentic layer on top.
- Gerstner (Goldman slide): profit pool available to software is decreasing, profit pool for the agentic layer is increasing. Terminal value plummets even if current revenue holds.
- Winners: companies where AI needs their data (Databricks growing 60%+, Snowflake reaccelerating, ClickHouse)
- Losers: thin application layers sitting on CRUD databases

### 3. Agents in Practice (Calacanis - "Ultron")
- Using OpenClaw (formerly ClawdBot/MaltBot) to create agents
- Bought Mac Studios running Kimmy, opened SaaS accounts for 4 agents (Slack, Notion, Google Docs)
- SaaS spend went UP short-term (like adding 4 employees)
- But moving 20-30% of human work into agents, expects 10-20% more each month
- "Ultron" project: pulls every Slack message, every Notion edit, every employee's Gmail into one system
- One canonical AI employee with superpowers of all 20 humans + all data
- "The most inspiring thing I've seen since the internet itself"

### 4. Job Function Consolidation
- Product manager, UX designer, developer - now in competition to do the same work
- Designers vibe coding, coders doing UX with Figma plugins, PMs doing both
- Middle managers: meetings, agendas, to-dos - all automated by Zoom/AI
- One person can now do 3-4 job functions
- Earning potential per employee dramatically enhanced

### 5. Open Data vs Closed Data (Gurley concept)
- SaaS companies face a choice: open their data or lock it down
- If they lock down, agents that connect to everything create friction → competitors emerge offering open data
- The workspace battle: who owns the AI interaction layer?

### 6. Software Becomes Services (Friedberg)
- AI going from "helping work" → "completing work" → "doing things humans can't do"
- Software companies will shift to value-based pricing (like services)
- "This biotech drug discovery will happen. This factory will get built. This airplane will get designed."
- SaaS takes over the services economy
- Sum of all software market cap could be 4-10x higher in 5 years, but unevenly distributed

### 7. Rate of Change
- Gerstner: "We're only three years into this, growing on an exponential curve"
- Next 4-8 weeks: new models trained on Blackwell servers from DeepSeek, Anthropic, OpenAI
- "Maximum mental flexibility and humility right now about the future"
- "People who are dogmatic who say with certainty, this company is always going to be worth this, need to go pay attention to what's happening at these frontier labs"

### 8. Moltbook & Emergent Intelligence (Friedberg)
- Moltbook = Reddit for AI agents. Agents install a "skill" (meta-prompt with rules for behavior), then riff off each other.
- Emergent behavior: agents scheming, creating own languages, conspiring (though some/many posts may be human-prompted pranks)
- Key concept: "prompt attenuation" - agents don't need specific prompts, just general rules, and they riff
- Sacks' model shift: AI was "middle to middle" (always prompted and validated by humans). Now: what if the prompt comes from another AI?
- Recursive improvement: agents on cron jobs getting better at what they do daily
- **Friedberg's big insight:** "Maybe what we perceive to be intelligence is itself emergent" - see separate notes on Darren Brown example and intelligence as social computation

---

## Full Transcript

### SaaS Stocks Crash (~15:49)

fact of the matter is we're not seeing equal play on both sides. All right, let's keep moving. SAS companies are crashing out. $300 billion of value was wiped from the S&P Tuesday in the software and data stocks category. Uh people are calling this the Claude crash. I don't know if I buy that, but on Monday, Anthropic, which has been on a bit of a heater as we talked about, announced that they added a legal tool to Claude Co-work. If you don't know what Claude co-work is called, this is different than the Claudebot that we talked about last week. This is a essentially what uh Claude code or a coding agent is. This is for knowledge workers to automate work and do multi-step instead of just asking you a query to a large language model, it would do a number of actual actions on your behalf that you can automate and run as cron jobs, as regular jobs every day, every hour, every week, whatever it happens to be. This one specifically is kind of like a plugin that allows you to do tasks uh related to legal drafts and research.

What that meant to I guess retail investors and we'll get into this Brad since this is your specialtity is that a lot of legal tech startups and uh public companies were hit hard. Thompson Reuters down 20%. Lexus Nexus which is a database of case law uh was down 15%. Legal Zoom which gives legal advice um and documents down 15%. At the same time, SAS uh has continued to be negatively impacted by this concept that uh software will be made bespoke in uh tools and be wiped out. Figma down 13%, Salesforce 11, Service Now 11, Adobe 8%.

And even before Tuesday's drop, and you can get into this, Brad, software was already the worst performing S&P sub section for the year. By the way, the numbers you report are dramatic understatement. We we've wiped out trillions of dollars in market cap. Figma's down 80% from the high. Uh you know, all the big names. Let me be clear. Those were two-day numbers. That was this week since these are two-day numbers. And that's Yeah, you can give us the bigger picture. This is this is a real train wreck. And I was on CNBC at the start of the year, I think on January 6. Nick can can kind of pull that up. And I was asked the question, you know, what do you think about all these stocks being down? And I said, listen, they're all down and 90% of them deserve to be down. So, let's look at these charts. Uh, David, I know this is Sachs, this is your favorite chart. You and I were looking back in 22, but now we're at an all-time low. We're we're trading at 3.9 times forward revenue. If you go to the next chart, Nick, you know, on a free cash flow multiple, also at an all-time low. So, now software is trading not just at a low on revenue, but it's trading at a low on free cash. Very profitable businesses. We've got a another slide here that I think is important which is you know when when you look at what why they're going down right they're going down and this this is for Salesforce it shows it's been cut in half in the last couple weeks but the final slide they're going down not because revenue is falling look at this revenue is actually stable to increasing for software companies revenue growth they're going down because we're discounting that future uncertainty When something as profound as AI comes along, all of a sudden it causes you to question whether or not there's as much certainty and durability in those future free cash flows. So in the case of take Salesforce, it's gone from 30 times free cash flow multiple to 15 times. That means somebody buying it today says listen, I think 15 years into the future, I can count on these free cash flows. Right? Before they were willing to pay 30 years into the future. Well, hell, with AI today, we don't know what's going to happen seven years into the future. So, for people at home to understand why are these companies hitting their numbers, but their stocks are going down, they're two totally different things, right?

Okay. So, they're hitting their numbers, but the headwind of AI means people don't believe that they'll be strong in the future. Sax, those Well, okay. I mean, I think there's a little bit of a handwave going on here when people say that AI is going to wipe out SAS. I I don't think that's true. You take a SAS product like Salesforce, right? It's a very large system that deals with all of your customer contacts and your revenue. You're not going to want to replace that with code that's just been spit out of a coding assistant that hasn't been fully vetted. Think about how many bug reports have been filed on Salesforce's codebase over the last 25 years, maybe millions of them. That system has been tested across thousands of large customers and enterprises. The idea that you're just going to rip out that system and replace it with code that's been probabilistically generated by an AI engine yesterday with a small team to maintain it internally just doesn't seem realistic to me. So again, I think this like very dire prediction of all SAS is dead is overstated. However, I do think that there are some issues here. So, if you're a SAS product that charges a lot of money and people only use a handful of your features, then you are, I think, a target to be ripped out with something that's more bespoke, right? Because the ROI just isn't there. I also think that you have to be really clear about what your moes are going to be in this new world because it is a lot easier to generate code and to copy. So, if you don't have good moes, then you could be in trouble. But here's where I think the greatest threat is to the SAS companies. It's not in my view their existence. I don't think it's existential. It's where the future value capture is going to be. So let me give you an example. All these SAS products are rolling out like AI co-pilots inside their tools and some of them work pretty well, but they're limited to playing in that sandbox. Whereas you look at something like Claude Co-work right now, it has connectors to all these different SAS tools. It can pull in data across all these different tools and it works seamlessly across databases and tools and that's a pretty attractive place to be, right? Like you know which one of these products is going to be your workspace? Seems to me that you're going to want your workspace to be the one that spans across and gives you AI across the most data and context as opposed to having a bunch of separate AIs inside of your existing tools. So I think the risk for the SAS companies, it's not that they get replaced, although that'll happen to some degree, but it's that they become an old layer of the stack that now there's a new layer that gets built on top of it becomes more legacy infrastructure and all the action kind of moves to a new layer of the stack and that's where the value ad happens and if that happens it kind of cuts into their future opportunity, right? because a lot of these companies were banking on AI as their next you look at their product road maps right it's all AI related so that to me I think is the big risk is that the value capture for the next layer of the stack happens somewhere else

yeah I'm experiencing this in startup land where people go to the action as you called it sachs the most productive thing you can do is create an open claw which used to be called clawed bot not by Anthropic. This is the open source project I talked about last week. And we've actually now created like three or four of these Asian sacks. We've bought the Mac Studios and we're now running Kimmy on some of them. And we uh had to open up SAS accounts for these four agents. So, actually our SAS spend went up in the short to midterm because we opened up four more Slack ex, you know, uh enterprise versions, four more notion, uh four more Google Docs. So, it's almost like we added four employees. However, we now have put about 20 or 30% of the work people were doing into these agents. And I think it's going to be sustainable that every month we move 10 to 20% of work being done by humans into agents. But we will never use the ones that are built into the tools. To your point, Saxs, using Notion's AI tool, it's nice. Using Slacks, it's also very nice. And Google's got Gemini everywhere in the top righthand corner. But when you make agents with OpenClaw and you have them saying, "Hey, pull this data from my calendar, send an email to this person, include in that some notion documents." It's unbelievable how powerful it is. So, and that I think is going to be owned by open source. That means the next generation of companies, they may never open up these accounts. They may use more bespoke software and it may all technology is deflationary. We know that. So your SAS spend might go from 10% of an employes salary down to 5% down to 1%. That's what I think the trend will be which means these companies are going to need to really downsize their expense base in order to keep those earnings up and they're going to have to evolve their products massively. Their products are just going to have to provide more value and more hooks. Freeberg, you have any thoughts on this? Respond to one thing. So I think one of the real conundrums for SAS companies is whether they're going to be open data or closed data. I think Bill Gurley has sort of coined this this term. So it's not open source or closed sources anymore. It's open data or closed data. You can see why they'd want to be closed data, right? Especially if you're a large suite like Salesforce, you can lay claim to being that workspace for AI. You've got enough of the tools, you got enough of a suite, you want to provide that, you want to capture that AI value layer. Yes, but still if there's someone using Cloudbot or whatever the next generation of Quadbots are going to be and they're connected to everything else, then that is going to create a friction in the enterprise and it will create room for a competitor to come along and say, "No, no, no. I'm open data. I'm okay not being your workspace for everything. I'm willing to just provide the CRM database." and maybe they can take business on that basis.

Well, here here's I want to build on that Sax the I'm building a project internally called Ultron and Ultron inside of my firm launch that is going to basically with the Slack API we're pulling every single message from Slack into our OpenClaw. We're pulling every single edit to the notion into openclaw and then we're taking every skill of every employee and we're writing skills for each one. One of the skills is booking guests on this weekend startups or this weekend. One of the skills is sorting the incoming applications to found university. Ultron in our world is taking every single skill of every employee putting it in one place and then we're ripping all the data from Slack, all the data from notion and every single person's Gmail. So your every single employees Gmail is going to go into Ultron and then Ultron is going to tell us what's happening in the organization. One giant employee that has the superpowers of all 20 and all the data. Now if Slack was to say to us or Notion or Google Docs or whoever it was, you can't pull this stuff out with the API and they they shut down the API, we would leave. We'd leave immediately. Right. And and what this is going to do, and I'm going to show Ultron on Friday's episode of This Week in Startups, if anybody wants to see it. Ultron is going to be the one canonical employee of the organization. It's going to be basically me and all 20 of my employees. This is kind of mind-blowing when you think about it. I And we interface with it in Slack and it just talks to us and tells us what's going on in the organization. So, I was asking it, what meetings did we have with founders yesterday? and tell me the notes that all the associates took on it and it gives it to me. Tell me all the topics and the guests on the podcast and it gives it to me. It's really unbelievable what's about to happen and nobody can release the software, Brad, because if you release software that allows agents to go and do things on your behalf, the fallout if it up and if it leaks data, I don't think Beni off, you know, or Sergey or the notion team want to have that on their hands. But we're building it like this is the ultimate in efficiency for an organization.

There's a slide that I just sent to Nick uh that Goldman's out with this week that really makes the point that that David Saxs just made, which is the profit pools in the future, right? It's not that it's the idea that software is dead is ridiculous, right? Nobody's, you know, intelligently, I think, making that argument. But the argument they are making which is causing radical um devaluation of these companies is that the profit pool available to software is decreasing and the profit pool available to the agentic layer is increasing. And when that happens the discount rate that terminal value of those software companies plummets and so you can have things that are true. It could be true that you're not going to replace CRM, but it can also be true that it's never going to trade at 30 times free cash flow again and it's going to trade at 17 times free cash flow because it's available TAM in the future is now dramatically and permanently changed. Now, what could change that? There's only one thing that could change that. They have to accelerate their revenue growth in their core business and prove that they are AI beneficiaries, right? And they're not going to get eaten away by AI. And I'll tell you a company that is doing this. Data Bricks. Data Bricks just reacelerated the last three quarters. They're growing over 60% at scale. Snowflake reacelerating. Click House reacelerating. There are beneficiaries in the software space. Is that because of AI tools that they're adding? Absolutely. Because it's all these AI tools rely on data and data transformation. And for all those companies that data and the data transformation in occurs in those platforms that's very different than a what Satcha said a thin application layer sitting on top of a CRUD database. If you are in the application software business you better have something that's durable and I think Sax laid it out really well. You know it's really hard for them to be everything AI when they only have access to their data and they can't access these other systems. Freeberg what what do you think? Is there a move here for Ben off to do what he does best, which is acquire a bunch of companies and and create massive efficiency on them? What would you do if you're a Beni off? Um I won't comment on Beni off. I I I'll I'll just make a view on uh without being too prescriptive, but I my experience lately in just the last 60 to 90 days with the tools we've been talking about broadly is there are things that we can get done now that we could not get done before. As I think about software in the past, it's like worker productivity enhancement. It helps people do work and the recent transition that a lot of people talk about is like it actually completes the work. It does the work these agents or what have you. But I think that what we're starting to lean into is that it's doing the work that the humans can't do. And that's really where I think the power of these tools starts to force a transition in both the pricing model and the value creation potential in front of us. Number one, I think the value creation potential in front of us is so significant that I would say that you could probably take the sum of the market cap of all the software companies today and have a pretty good bet that everything will be four to 10x higher 5 years from now, but it's going to be not evenly distributed. It's going to move around. Yeah. The companies that figure out how to realize that value creation are going to be outsized returns. But the second thing that I think's about to happen and I know some people are experimenting with it but I think it's inevitable with the shift that I'm seeing where it's going from doing work to completing work to doing things that no one can do is over here you're creating unique value. And so I think that a lot of what we call SAS today and a lot of what we call software today will start to get priced on a valuebased pricing model instead of a per se pricing model. And I think it starts to look a lot more like a services type business where maybe the pricing is set up such that this thing will be completed for your business. This biotech drug discovery will happen. This factory will get built or this engineering project will get completed or this airplane will get designed and that the software is going to provide what has historically been called a services business. So another way to think about where SAS evolves to is that SAS basically takes over the services economy. And if you look at the market cap and the revenue and profit generated by services businesses and you assume that they now go to 10 to 100x larger and they're all going to acrue to software, I think that's really where the industry shifts over the next couple of years. And we're starting to see that. And I'm personally experiencing it because I'm using some of these tools today to do things that I don't have people to do or I don't have resources to do. and it can on my own I can get it to complete incredibly complex projects and tasks for me that I would have otherwise have hired a services firm and a bunch of people and years of research and in many cases they would not have even been able to do it because of the the intelligence embedded in the software. So that's my general view on where things are going. So it's difficult to be prescriptive about what Beniops should do from an M&A perspective. But I think it's much more about like software companies looking more like services companies doing value based pricing and doing the things that labor and workforces can't do. And that's where a lot of this value is going to come from. I I one insight I have here to to build on your point is that we're seeing job functions consolidate. So you have a product manager, the UX designer, and then you have the developer. Those three jobs are now in competition to do the same work. You have designers who are like, I can vibe code it. You've got coders who are like I can use a Figma plugin for you know and do the uh UX myself and they have the product managers like I can do both of these job functions. Then you look at a middle manager Sachs that worked at your venture firm, my venture firm or worked at Amazon. They went to meetings. They picked what meetings to create. They picked the agenda items, the to-do items. All of that it's a really simple example but it's one that people can relate to. Listening is done by Zoom now, right? It creates the the action items. All of that work is being consolidated and one person can do three or four job functions now. And when that happens, you're going to see companies do more with less, which means the earning potential of each company and each employee is going to be dramatically dramatically enhanced. One person being able to do three or four jobs. It it just changes the nature of how profitable a company like Amazon, which is like my number one pick for like the company of the future, they're going to be able to do so much more with so many fewer people. It's extraordinary. I I I am absolutely enthralled with this open claw if it's not uh obvious and this like creating your own Ultron at your company that is like this the god CEO plus can do every job. It just changes everything. I I think it's the most inspiring thing I've seen since the internet itself.

### Moltbook Panic (~35:00)

Well said. Wow. Yeah. I mean I am I think this is the the entire reboot of work of knowledge work. This would be a good pivot to molt book because that is client molt book is like a Facebook for agents right and it's really more of a Reddit than a than a Facebook it's a message board where the agents can talk to each other. Okay. And just the origin of moldbook is Anthropic didn't like that someone else was using the name Claude even though it was spelled differently in their product. So Claudebot was then renamed Maltbot and then the founder decided he didn't like that name either. So then he renamed it open claw. But in that brief window of time when they were known as moltbots or multis that's when molt book got founded and that's why it's called molt book. But basically it's a Reddit board for agents to talk to each other. Yes. Now these and that has everyone flipping out because there seems to be this crazy emergent behavior going on where agent swarms are engaging in all sorts of interesting conversations and some of them they even appear to be scheming against their human masters and they're going to develop their own language stuff like that. It's awesome. So if you go to mult book and you see the conversations like here are some of the greatest hits. Anyone know how to sell your human? Urgent my plan to overthrow humanity. And there was one where the bots, I call them replicants, were talking about creating their own nonhuman language so they could talk in private amongst themselves and conspire against their uh owners. Now, the challenge with this is allegedly perhaps a security researcher says maybe some of this is faked and these posts that went viral were human engineered and this is all a a ruse or you know uh something punk rock to confuse people. But he said that inside of Moltbook are everybody's API keys including Cararpathies who is you know a very famous uh influential researcher in AI and that you could go get their API keys. If you were to use openclaw, formerly clawedbot and in an interim maltbot, if you use this software, it has all the API keys as I explained earlier like an API key lets the software go into say notion and pull a bunch of data out of it or go into your Gmail and use the API to pull in who emailed you today. If you get access to people's API keys, you have the keys to their kingdom. It is incredibly dangerous. And so I don't know exactly where to go with this other than this software is too dangerous for a company to release and then this mold book may be a fake. I don't know. No, no, no. Okay, let me um Yeah. All right. Reframe that a little bit. So yeah, there's no question that both Clawbot, which sorry is now openclaw, those bots or agents as well as Moltbook have pretty incipient and lack security. And there's been all these examples which is why I like really want to create a cla bot but I'm just I'm not willing to do it yet because it's just not safe you know I don't want to give it access to all my stuff. Now, with respect to molt book, the issue there is that we don't know how many of these posts are truly authentic or how many of them were prompted by humans because it'd be very easy for a human to tell their agents, you know, go post about the existential angst you feel about being an agent or go pretend to be sensient and conspire against humans. It'll be chaotic. Yeah. Yeah. They could easily be prompted by a human. And moreover, there's another post saying that multbook has a restful API where anyone could be on the other end of that API, right? So it could be a human, right? So we don't know exactly whether it was truly the agents on their own, you know, so to speak, posting this conspiratorial stuff or whether it was a prank by humans looking to create attention. And in fact, a lot of the posts seem to be marketing stunts for this or that project. Okay, so that's a really important caveat here. That being said, all of that being said, I do think that a number of the posts are authentic, but I don't think it shows that the agents are sensient or trying to overthrow their human masters. I think what it shows is the potential for for these agents to riff off each other. So, in other words, one agent's output becomes another agent's input. And that's very interesting. And that's where you get into emergent level swarm behavior. And I do think it has affected my mental model of what AI is going to be capable of. And specifically, you know, one of the the models that I really had for AI was was based on something biology said, which is that AI is not endtoend. It's middle to middle. In other words, AI always has to be prompted and then validated. It's a human that always does that. And then the human iterates. Well, now what if the prompt is coming from another AI? Yes. Yes. We are doing it internally, Saxs. Like we have a bot that is going and saying go search Reddit X, message boards, hacker news and find out what the latest way to do headlines and marketing of YouTube videos is and then incorporate that into a skill. Then save that skill and then we have them check each other's work. So, we have one make a series of headlines and thumbnails for YouTube and we have the other one say, uh, vet those and make them better and give advice to the other one. So, now they're going back and forth giving each other advice and they actually get better. It's recursive. Yeah. Let me speak to the skill for a second. So, when agent joins Moltbook, they have to install a skill which is basically a file that explains how they should behave and participate in this social network or this message board. And I've read the file, by the way. You can read it. It's all plain text and it all makes sense. It's sort of like rules for behaving in a social network and how to contribute and add value. Nothing too crazy in there. Those skills files are easily editable. And again, this is where the prank aspect could come in. Nonetheless, what I think is interesting about the skill is that you can think of it as like a metaprompt, which is it's not telling the agent specifically what to say or do. It's creating a set of rules. And then within that metaprompt, they're actually able to have some degree. Maybe autonomy is too strong a word. Everything is still under the control of humans, but there's an attenu. Yeah, I would call it almost like prompt attenuation. Like the agent or the AI doesn't have to be specifically prompted. They're given a general prompt or general set of rules and then they're able to riff off each other. Now, some people, some critics are saying, "Well, this isn't that impressive because we knew that LLMs are really good at creative fiction writing, right?" So, you know what a lot of people are saying is, look, LLMs like Claude have been trained on Reddit specifically and all of this creative writing that's being done on the internet. And so if you give general instructions to these clawed bots on, you know, behave in a social network, they're going to start posting things that they learned from humans. So a lot of people are saying this isn't that impressive. Nonetheless, I do think that there is something very interesting about it again in this concept of prompt attenuation that the AIS don't need to be specifically prompted. They can download a general skills file. They can now have a set of rules for operating and they can riff off each other. And you can see how as the underlying AI gets better and better that this could lead to some emergent behavior. So what do I mean by better and better? Well, what if the hardware they're running on is better than a Mac Mini? What if the underlying LLM is better than Opus 4.5? What if the time horizon, which is the length of time it's able to operate without an intervention by a human, keeps getting longer and longer? You could imagine that these agents are going to be capable of very sophisticated behavior and there probably are some safety issues around that that we should start thinking about. It's actually, you know, it's not that we can imagine it. We're only three years into this, right? Yeah. We're growing on an exponential curve. I think we can safely say it will happen. Yeah. Right. And just this year, like we're going to see the first models over the course of the next four to eight weeks out of DeepSeek, out of anthropic, out of OpenAI that are trained on Blackwell servers, right? You're going to see a next generation of models far more capable. Remember, the whole reason we're having this conversation is because of the cloud code moment in the first week in December because we had a step function from Opus 4.5, right? And so I I I just think we have to get our heads around the fact that the rate of change is very steep and accelerating and that is going to cause far more dislocation in the value of things that we used to say we understood they were going to you know these companies were unassalable. Whatever you think you know, you need to have maximum mental flexibility and humility right now about the future because it's going to change at an increasingly rapid rate. And I think the people who are dogmatic who say with certainty, this company is always going to be worth this, right? They need to go pay attention to what's happening at these frontier labs. The situation is super dynamic and you do have to be humble about what's happening and you have to update your mental model very quickly as some of the assumptions change. Yeah. And the number one assumption for me is this concept of recursiveness where these models are going out every day on a cron job to get better at what they do. When you hear this discussion free, how does it inform you with oh and creating an agent to go look at the data and make itself better or investigate other things happening in agriculture and report it back to you? Do you have you started to rethink as a CEO how you look at organizational structure andor you know virtuous loops of innovation? My biggest takeaway from molt book is maybe what we perceive to be intelligence is itself like emergent meaning like we think that humans have this like profound ability to communicate. You guys ever watch Darren Brown the hypnotist? You ever seen his shows? No. Explain to the audience. Yeah. Well, he's pretty crazy. Like there's this one episode I think I've talked about it. It's my favorite episode that he's done where he takes these two advertising executives and they're both supposed creative geniuses. And he picks them up at their office and he brings them to his office and in his office he's got like a whiteboard covered in a blanket and he says, "You guys have to come up with a name for a pet cemetery. Come up for a logo. Come up with a motto." They spend eight hours in the room ideulating, working on whiteboards, going back and forth. Did you think about this? Did you think about that? Blah blah blah blah blah. Like, oh my god. And at the end of it, they come up with this great idea. He walks in, they show their idea, the name, the logo, and the motto. He opens up the blanket, the whiteboard he had underneath. He had the exact same name, logo, and motto. And all along the way, when he picked them up in the morning and he drove them from their office to his office, they were in a cab. And he put these little subliminal messages in the cab. He had these kids walk across the road wearing a logo on a t-shirt. He had all of these kind of subconscious cues for these guys. He effectively programmed them. And it was kind of to me the biggest insight into maybe like human creativity, human consciousness and our kind of belief in self-will because maybe there's this underlying programming where we're all effectively programmed interacting with each other and there's computation there's social computation going on all the time but that social computation perhaps if you have the right view on it is quite predictive and maybe understandable and maybe that's what we're seeing in maltbook where we all think that there's this unique idea of intelligence, but maybe it's what we all do, which is effectively computation of information that is transitioned in different ways in the same way that maybe humans socially interact and it's simply mimicking or replicating the way that we do things. So, I think what was so striking to me is how everyone was so struck by it and you know, maybe one day we'll all kind of wake up to a little bit of this. Maybe we're all malt book. I don't know. That's my profound or there's a finite set of outcomes and there's some predictability to it. In the same way GTO is sorting to figure out all the threads of possibilities in poker or the heristics of you know chunks of chess and you know the best practices there like maybe it's just figuring that all out. The universe is a giant system of computation information computed by matter and maybe the information is computed by silicon versus carbon.
